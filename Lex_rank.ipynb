{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from gensim.models.wrappers.fasttext import FastText as ft\n",
    "from scipy.spatial import distance\n",
    "import pandas as pd\n",
    "import MeCab\n",
    "\n",
    "\n",
    "def word2id(bow, word_id):\n",
    "    for w in bow:\n",
    "        if w not in word_id:\n",
    "            word_id[w] = len(word_id)\n",
    "    return word_id\n",
    "\n",
    "def compute_tf(sentences, word_id):\n",
    "    tf = np.zeros([len(sentences), len(word_id)])\n",
    "\n",
    "    for i in range(len(sentences)):\n",
    "        for w in sentences[i]:\n",
    "            tf[i][word_id[w]] += 1\n",
    "    return tf\n",
    "\n",
    "def compute_df(sentences, word_id):\n",
    "    df = np.zeros(len(word_id))\n",
    "\n",
    "    for i in range(len(sentences)):\n",
    "        exist = {}\n",
    "        for w in sentences[i]:\n",
    "            if w not in exist:\n",
    "                df[word_id[w]] += 1\n",
    "                exist[w] = 1\n",
    "            else:\n",
    "                continue\n",
    "    return df\n",
    "\n",
    "def compute_idf(sentences, word_id):\n",
    "    idf = np.zeros(len(word_id))\n",
    "    df = compute_df(sentences, word_id)\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        idf[i] = np.log(len(sentences)/df[i]) + 1\n",
    "    return idf\n",
    "\n",
    "def compute_tfidf(sentences):\n",
    "    word_id = {}\n",
    "\n",
    "    for sent in sentences:\n",
    "        word_id = word2id(sent, word_id)\n",
    "\n",
    "    tf = compute_tf(sentences, word_id)\n",
    "    idf = compute_idf(sentences, word_id)\n",
    "\n",
    "    tf_idf = np.zeros([len(sentences), len(word_id)])\n",
    "\n",
    "    for i in range(len(sentences)):\n",
    "        tf_idf[i] = tf[i] * idf\n",
    "\n",
    "    return tf_idf\n",
    "\n",
    "def compute_cosine(v1, v2):\n",
    "\n",
    "    return 1 - distance.cosine(v1, v2)\n",
    "\n",
    "def sent2vec(bow, model_w):\n",
    "\n",
    "    vector = np.zeros(100)\n",
    "    N = len(bow)\n",
    "\n",
    "    for b in bow:\n",
    "        try:\n",
    "            vector += model_w[b]\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    vector = vector / float(N)\n",
    "\n",
    "    return vector\n",
    "\n",
    "def compute_word2vec(sentences):\n",
    "\n",
    "    model = ft.load_fasttext_format(\"../Downloads/model\")\n",
    "    \n",
    "    vector = np.zeros([len(sentences), 100])\n",
    "\n",
    "    for i in range(len(sentences)):\n",
    "        vector[i] = sent2vec(sentences[i], model_w)\n",
    "\n",
    "    return vector\n",
    "\n",
    "def lexrank(sentences, N, threshold, vectorizer):\n",
    "\n",
    "    CosineMatrix = np.zeros([N, N])\n",
    "    degree = np.zeros(N)\n",
    "    L = np.zeros(N)\n",
    "\n",
    "    if vectorizer == \"tf-idf\":\n",
    "        vector = compute_tfidf(sentences)\n",
    "    elif vectorizer == \"word2vec\":\n",
    "        vector = compute_word2vec(sentences)\n",
    "\n",
    "    # Computing Adjacency Matrix                                                                                                                                         \n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            CosineMatrix[i,j] = compute_cosine(vector[i], vector[j])\n",
    "            if CosineMatrix[i,j] > threshold:\n",
    "                CosineMatrix[i,j] = 1\n",
    "                degree[i] += 1\n",
    "            else:\n",
    "                CosineMatrix[i,j] = 0\n",
    "\n",
    "    # Computing LexRank Score                                                                                                                                            \n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            CosineMatrix[i,j] = CosineMatrix[i,j] / degree[i]\n",
    "\n",
    "    L = PowerMethod(CosineMatrix, N, err_tol=10e-6)\n",
    "\n",
    "    return L\n",
    "\n",
    "def PowerMethod(CosineMatrix, N, err_tol):\n",
    "\n",
    "    p_old = np.array([1.0/N]*N)\n",
    "    err = 1\n",
    "\n",
    "    while err > err_tol:\n",
    "        err = 1\n",
    "        p = np.dot(CosineMatrix.T, p_old)\n",
    "        err = np.linalg.norm(p - p_old)\n",
    "        p_old = p\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.]\n"
     ]
    }
   ],
   "source": [
    "b = Hoge()\n",
    "b.hoge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Lexrank():\n",
    "    def __init__(self, sentences):\n",
    "    \n",
    "        self.sent = sentences\n",
    "    \n",
    "    def __tf_idf_(self):\n",
    "        self.tmp = {}\n",
    "        \n",
    "        for i in self.sent:\n",
    "            tmp = self.__word2id_()\n",
    "        \n",
    "    def compute_tfidf(sentences):\n",
    "    word_id = {}\n",
    "\n",
    "    for sent in sentences:\n",
    "        word_id = word2id(sent, word_id)\n",
    "\n",
    "    tf = compute_tf(sentences, word_id)\n",
    "    idf = compute_idf(sentences, word_id)\n",
    "\n",
    "    tf_idf = np.zeros([len(sentences), len(word_id)])\n",
    "\n",
    "    for i in range(len(sentences)):\n",
    "        tf_idf[i] = tf[i] * idf\n",
    "\n",
    "    return tf_idf\n",
    "    \n",
    "    def fit(self,threshold,N=0,vectorizer='tf-idf'):\n",
    "        if N == 0:\n",
    "            self.N = len(self.sent)\n",
    "        \n",
    "        self.cos_matrix = np.zeros((self.N,self.N))\n",
    "        self.__degree_ = np.zeros(self.N)\n",
    "        self.score = np.zeros(self.N)\n",
    "        \n",
    "        if vectorizer == 'tf-idf':\n",
    "            self.vector = self.__tf_idf_()\n",
    "        else:\n",
    "            sys.exit('Vectorizer Error Occured!')\n",
    "        \n",
    "        \n",
    "            \n",
    "            \n",
    "    CosineMatrix = np.zeros([N, N])\n",
    "    degree = np.zeros(N)\n",
    "    L = np.zeros(N)\n",
    "\n",
    "    if vectorizer == \"tf-idf\":\n",
    "        vector = compute_tfidf(sentences)\n",
    "    elif vectorizer == \"word2vec\":\n",
    "        vector = compute_word2vec(sentences)\n",
    "\n",
    "    # Computing Adjacency Matrix                                                                                                                                         \n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            CosineMatrix[i,j] = compute_cosine(vector[i], vector[j])\n",
    "            if CosineMatrix[i,j] > threshold:\n",
    "                CosineMatrix[i,j] = 1\n",
    "                degree[i] += 1\n",
    "            else:\n",
    "                CosineMatrix[i,j] = 0\n",
    "\n",
    "    # Computing LexRank Score                                                                                                                                            \n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            CosineMatrix[i,j] = CosineMatrix[i,j] / degree[i]\n",
    "\n",
    "    L = PowerMethod(CosineMatrix, N, err_tol=10e-6)\n",
    "\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "power_method() missing 1 required positional argument: 'e'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-824300d400a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlex_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-115-351924504ff6>\u001b[0m in \u001b[0;36mlex_rank\u001b[0;34m(sentences, n, t)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mcosine_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdegrees\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpower_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosine_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: power_method() missing 1 required positional argument: 'e'"
     ]
    }
   ],
   "source": [
    "rank = lex_rank(sent1,i,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kuchikomi = pd.read_csv('./test.csv',encoding=\"SHIFT-JIS\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp = kuchikomi[0].tolist()\n",
    "sentences = [extractKeyword(tmp[x]) for x in range(len(tmp))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "選考はES、GDだけであるため、他の外資コンサルインターンへ参加するより選考の回数は少ないです。 0.0871722937023\n",
      "選考はESとGDだけだったのですが大量の人が切られていたので、いかに目を引くかが求められていたと思う。 0.0871631538312\n",
      "特にGDの場合は、参加する前にグGD対策イベントやセミナーなどに参加してGDの雰囲気を把握し、その中で自分がもっとも発揮できる役割を認識しておくと良いと思います。 0.087161761001\n",
      "そして、業務の中で、経営者だけでなく現場の方や技術者の方ともお話しすることが多いため、幅広いタイプの人と接するコミュニケーション能力も見られていたと感じます。 0.0622220541205\n",
      "また、ES以降の選考に筆記試験はなく、GDのみであるため、学生の質にばらつきがあった。 0.0498400476069\n",
      "しかし、その分一つ一つの選考を入念に対策をしておかないと、インターンへの参加が難しいと思います。 0.0498071980665\n",
      "もちろん理論的思考は当たり前にできていることが条件だと思った。 0.047619047619\n",
      "特に、東京大、京都大、早大、慶大などの高学歴で理系院生であれば、基本的に通過できるはずである。 0.047619047619\n",
      "ESは学歴フィルターの役割を果たしておりそこまで重視されていないように思う。 0.047619047619\n",
      "社員の方々も自分たちのコンサルティングスタイルを、ノコギリで木を切り倒すよう粘り強く問題にチャレンジすると述べており、泥臭く課題に取り組む姿勢は見られていたと感じました。 0.047619047619\n",
      "あきらめずに考え続けることができるか。この2点が重要だと思う。 0.0374503671586\n",
      "そういった学生をいかにまとめあげ、議論を前に進められるかが重要視されていたように思う。 0.0374207161698\n",
      "しかし、皆発言回数は多かったため、GDでも一定以上の発言回数はみられているのではないかと思う。 0.0373569328739\n",
      "選考時間は長いが、ずっと見られているので集中を切らさず、最後まで自分の力を発揮して、楽しく過ごすことが大切だと思う。 0.0373564770121\n",
      "インターン参加者の雰囲気を見ると、それぞれ自分の考えと性格がはっきりしていたため、参加者のバランスも見ていたような気がする。 0.0373541286189\n",
      "特にどんな人が多いということはなく、様々な人が参加していた。 0.0373427615501\n",
      "またインターン後に、面接官だった社員の方になぜ受かったのか尋ねてみると、個人ワークの時点である程度みて、グループディスカッションに入っても十分やれているから合格したのだと教えていただけた。 0.0373427615501\n",
      "また、メーカーのコンサルティングが多い関係で、技術をいかに活用していくか考える場面が多く、柔軟な発想が求められることを述べておられました。 0.0373276656084\n",
      "粘り強さと発想の柔軟性、そしてコミュニケーション能力が特にみられていたと思います。 0.0373276656084\n",
      "多様な視点から考えることができるかどうか。 0.024975485623\n",
      "ただこれはGDの経験によるものが大きい。 0.0249023394221\n"
     ]
    }
   ],
   "source": [
    "hoge = lexrank(sentences,21,0.1,'tf-idf')\n",
    "for k in range(len(hoge)):\n",
    "    print(tmp[np.argsort(hoge)[::-1][k]], np.sort(hoge)[::-1][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 159 is out of bounds for axis 0 with size 21",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-a7c522e6e2db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhoge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhoge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 159 is out of bounds for axis 0 with size 21"
     ]
    }
   ],
   "source": [
    "np.argsort(hoge)[::-1][i], np.sort(hoge)[::-1][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extractKeyword(text):\n",
    "    tagger = MeCab.Tagger()\n",
    "    tagger.parse('')\n",
    "    node = tagger.parseToNode(text).next\n",
    "    keywords = []\n",
    "    while node:\n",
    "        if node.feature.split(\",\")[0] == \"名詞\":\n",
    "            keywords.append(node.surface)\n",
    "        node = node.next\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "名詞,サ変接続,*,*,*,*,選考,センコウ,センコー\n",
      "助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "名詞,固有名詞,一般,*,*,*,ES,イーエス,イーエス\n",
      "記号,読点,*,*,*,*,、,、,、\n",
      "名詞,固有名詞,一般,*,*,*,GD,ゴールデンドーン,ゴールデンドーン\n",
      "助詞,副助詞,*,*,*,*,だけ,ダケ,ダケ\n",
      "助動詞,*,*,*,特殊・ダ,連用形,だ,デ,デ\n",
      "助動詞,*,*,*,五段・ラ行アル,基本形,ある,アル,アル\n",
      "名詞,非自立,副詞可能,*,*,*,ため,タメ,タメ\n",
      "記号,読点,*,*,*,*,、,、,、\n",
      "名詞,一般,*,*,*,*,他,タ,タ\n",
      "助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "名詞,一般,*,*,*,*,外資,ガイシ,ガイシ\n",
      "名詞,一般,*,*,*,*,*\n",
      "助詞,格助詞,一般,*,*,*,へ,ヘ,エ\n",
      "名詞,サ変接続,*,*,*,*,参加,サンカ,サンカ\n",
      "動詞,自立,*,*,サ変・スル,基本形,する,スル,スル\n",
      "助詞,格助詞,一般,*,*,*,より,ヨリ,ヨリ\n",
      "名詞,サ変接続,*,*,*,*,選考,センコウ,センコー\n",
      "助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "名詞,一般,*,*,*,*,回数,カイスウ,カイスー\n",
      "助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "形容詞,自立,*,*,形容詞・アウオ段,基本形,少ない,スクナイ,スクナイ\n",
      "助動詞,*,*,*,特殊・デス,基本形,です,デス,デス\n",
      "記号,句点,*,*,*,*,。,。,。\n",
      "BOS/EOS,*,*,*,*,*,*,*,*\n",
      "['選考', 'は', 'ES', '、', 'GD', 'だけ', 'で', 'ある', 'ため', '、', '他', 'の', '外資', 'コンサルインターン', 'へ', '参加', 'する', 'より', '選考', 'の', '回数', 'は', '少ない', 'です', '。', '']\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "\n",
    "tagger = MeCab.Tagger('-Ochasen')\n",
    "tagger.parse('')\n",
    "node = tagger.parseToNode('選考はES、GDだけであるため、他の外資コンサルインターンへ参加するより選考の回数は少ないです。').next\n",
    "key = []\n",
    "while node:\n",
    "    print(node.feature)\n",
    "    key.append(node.surface)\n",
    "    node = node.next\n",
    "print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
